{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "from mne import viz\n",
    "from mne import io\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs, corrmap)\n",
    "import zipfile\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing participant files\n",
    "folder_names = []\n",
    "participants = sorted(os.listdir('./sourcedata'))\n",
    "for p in participants:\n",
    "    print(f'{p}:')\n",
    "    conditions = os.listdir(f'./sourcedata/{p}/eeg')\n",
    "    for c in conditions:\n",
    "        print(f'    -{c}')\n",
    "        folder_names.append(c)\n",
    "        file_names = os.listdir(f'./sourcedata/{p}/eeg/{c}')\n",
    "        for fname in file_names:\n",
    "            print(f'       <{fname}>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 20220607 1636\n"
     ]
    }
   ],
   "source": [
    "#------select-file------#\n",
    "project = 'derivative_project00'\n",
    "ID = 'MSICU07'\n",
    "task = 'RS_ST_Taken_Tennis'\n",
    "#-----------------------#\n",
    "\n",
    "\n",
    "source_path = f'./sourcedata/sub-{ID}/eeg/sub-{ID}_task-{task}_eeg' \n",
    "files = os.listdir(source_path)\n",
    "for file_name in files:\n",
    "    parts = file_name.split('.')\n",
    "    fname = parts[0]\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Searching for working directorys.\n",
      "    - No directory found. New directory made.\n",
      "\n",
      "(2) Unzipping files into prepoc directory.\n",
      "    - sub-MSICU07_task-RS_ST_Taken_Tennis sourcefile was unzipped to the participants working directory.\n",
      "    - sub-MSICU07_task-RS_ST_Taken_Tennis_eeg/Session 20220607 1636.mff was renamed with .mff suffix\n",
      "\n",
      "(3) loading metadata and downsampling for MSICU07_RS_ST_Taken_Tennis\n",
      "Reading EGI MFF Header from /imaging/owenlab/EGI_ICU/derivative_project00/PT/sub-MSICU07/eeg/sub-MSICU07_task-RS_ST_Taken_Tennis_eeg/Session 20220607 1636.mff...\n",
      "    Reading events ...\n",
      "    Assembling measurement info ...\n",
      "    Synthesizing trigger channel \"STI 014\" ...\n",
      "    Excluding events {sync} ...\n",
      "    Downsampling...\n",
      "    - The raw sampling frequincy is 250.0Hz.\n",
      "    - Cannot downsample because data is already sampled at 250Hz.\n",
      "\n",
      "(4) Loading data into memory...\n",
      "Reading 0 ... 496769  =      0.000 ...  1987.076 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>June 07, 2022  21:44:25 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>132 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>129 EEG, 6 Stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>signal1.bin</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:33:08 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawMff | signal1.bin, 135 x 496770 (1987.1 s), ~511.8 MB, data loaded>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a preproc directory from sourcefile\n",
    "print('(1) Searching for working directorys.')\n",
    "if 'HC' in ID:\n",
    "    new_path = f'./{project}/HC/sub-{ID}/eeg/sub-{ID}_task-{task}_eeg'\n",
    "else:\n",
    "    new_path = f'./{project}/PT/sub-{ID}/eeg/sub-{ID}_task-{task}_eeg'\n",
    "if not os.path.exists(f'./{new_path}'):\n",
    "    os.makedirs(f'{new_path}')\n",
    "    print('    - No directory found. New directory made.')\n",
    "else:\n",
    "    print('    - This directory already exists. \\n    - Continue with existing file.') \n",
    "\n",
    "#unzip source files to the participants working directory\n",
    "print('\\n(2) Unzipping files into prepoc directory.')         \n",
    "if not os.path.exists(f'./{new_path}/{fname}'):\n",
    "    with zipfile.ZipFile(f'{source_path}/{fname}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(new_path)\n",
    "        print (f'    - sub-{ID}_task-{task} sourcefile was unzipped to the participants working directory.')\n",
    "else:\n",
    "    print(f'    - Cannot unzip files because {fname} already exists.\\n    - Continue with existing file.')\n",
    "\n",
    "#Renaming the file       \n",
    "if not os.path.exists(f'./{new_path}/{fname}.mff'):\n",
    "    os.rename(f'{new_path}/{fname}', f'{new_path}/{fname}.mff')\n",
    "    print(f'    - sub-{ID}_task-{task}_eeg/{fname}.mff was renamed with .mff suffix')\n",
    "else:\n",
    "    print(f'    - cant rename file to .mff because {fname}.mff file already exisits. \\n    - Continuing with existing file')\n",
    "\n",
    "#Loading metadata\n",
    "print(f'\\n(3) loading metadata and downsampling for {ID}_{task}')\n",
    "data_path = f'{new_path}/{fname}.mff'\n",
    "raw = mne.io.read_raw_egi(data_path)\n",
    "raw\n",
    "\n",
    "#Downsampling to 250Hz\n",
    "data = raw.copy()\n",
    "raw_sfreq = raw.info['sfreq']\n",
    "data_sfreq = data.info['sfreq']\n",
    "print(f'    Downsampling...\\n    - The raw sampling frequincy is {raw_sfreq}Hz.')\n",
    "if data_sfreq == 250:\n",
    "    print('    - Cannot downsample because data is already sampled at 250Hz.')\n",
    "elif data_sfreq > 250:\n",
    "    data.resample(250)\n",
    "    print('    - Data was downsampled to 250Hz.')\n",
    "else:\n",
    "    print(f'    - Error: Data sampling frequency is {raw_sfreq}Hz.')\n",
    "    answer = input('      - Do you want to continue?:')\n",
    "    if answer.lower().startswith(\"y\"):\n",
    "        print(\"      - ok, carry on then\")\n",
    "    elif answer.lower().startswith(\"n\"):\n",
    "        print(\"      - ok, sayonnara\")\n",
    "        sys.exit()\n",
    "        \n",
    "#loading in data      \n",
    "print('\\n(4) Loading data into memory...')\n",
    "data.load_data() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital Events & Initial Crop\n",
    "redefine trigger events after cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 800x800 with 4 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Data timing...\n",
      "    - <RawMff | signal1.bin, 135 x 496770 (1987.1 s), ~511.8 MB, data loaded>\n",
      "    - time(s): 0.0 - 1987.076\n",
      "    - samples: 0 - 496769\n",
      "    -* Duration = 0hr : 33min : 07sec\n",
      "\n",
      "(2) Trigger Channels\n",
      "    - Trigger ch. 9   \n",
      "    - Trigger ch. 12  \n",
      "    - Trigger ch. 10  \n",
      "    - Trigger ch. 20  \n",
      "\n",
      "(3) Initial events\n",
      "4 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "    - initial_events_1: 6.232 s.\n",
      "    - initial_events_2: 600.236 s.\n",
      "    - initial_events_3: 1000.396 s.\n",
      "    - initial_events_4: 1708.172 s.\n"
     ]
    }
   ],
   "source": [
    "# Timeing\n",
    "print('(1) Data timing...\\n    -', data)\n",
    "print(f'    - time(s): {data.tmin} - {data.tmax}')\n",
    "print(f'    - samples: {data.first_samp} - {data.last_samp}')\n",
    "seconds = data.tmax\n",
    "seconds = seconds % (24 * 3600)\n",
    "hour = seconds // 3600\n",
    "seconds %= 3600\n",
    "minutes = seconds // 60\n",
    "seconds %= 60\n",
    "print(\"    -* Duration = %dhr : %02dmin : %02dsec\" % (hour, minutes, seconds))\n",
    "\n",
    "# Trigger Channels\n",
    "print('\\n(2) Trigger Channels')\n",
    "triggers = []\n",
    "for i in data.ch_names:\n",
    "    if not 'E' in i:\n",
    "        if not 'sync' in i:\n",
    "            if not 'STI' in i:\n",
    "                if not 'V' in i:\n",
    "                    print (\"    - Trigger ch.\",i)\n",
    "                    triggers.append(i)\n",
    "\n",
    "# Initial events\n",
    "print('\\n(3) Initial events')\n",
    "initial_events = mne.find_events(data, stim_channel='STI 014', initial_event=True)\n",
    "for i in range(initial_events.shape[0]):\n",
    "    exec('initial_events_'+str(i+1) +'='+ str(initial_events[i,0]/data.info['sfreq']))\n",
    "    exec(\"print('    - initial_events_' + str(i+1)+ ':', initial_events_\" + str(i+1)+\",'s.')\")\n",
    "\n",
    "\n",
    "# (4) crop\n",
    "\n",
    "# (5) Mark Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.crop(tmin = initial_events_1) #tmax = 380)\n",
    "#data.crop(tmin = initial_events_1, tmax = initial_events_6)\n",
    "start_time = data.first_samp/data.info['sfreq']\n",
    "\n",
    "\n",
    "print('(1) Data timing...\\n    -', data)\n",
    "print(f'    - time(s): {data.tmin} - {data.tmax}')\n",
    "print(f'    - samples: {data.first_samp} - {data.last_samp}')\n",
    "seconds = data.tmax\n",
    "seconds = seconds % (24 * 3600)\n",
    "hour = seconds // 3600\n",
    "seconds %= 3600\n",
    "minutes = seconds // 60\n",
    "seconds %= 60\n",
    "print(\"    -* Duration = %dhr : %02dmin : %02dsec\" % (hour, minutes, seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining trigger times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________\n",
      "--------------Trigger Channels_2--------------\n",
      "\n",
      "______________________________________________\n",
      "Ch. 12  \n",
      "    > Scrambled Start (s): 0.0 <\n",
      "\n",
      "______________________________________________\n",
      "Ch. 10  \n",
      "    > Taken Start (s): 631.808 <\n"
     ]
    }
   ],
   "source": [
    "#Assigning variables for event onset times\n",
    "#print('\\n(4) Assigning variables for event onset times:')\n",
    "print('\\n______________________________________________\\n--------------Trigger Channels_2--------------')\n",
    "for i in triggers:\n",
    "    print (\"\\n______________________________________________\\nCh.\", i)\n",
    "    if '09' in i: \n",
    "        with io.capture_output() as captured:\n",
    "            trig09=(mne.find_events(data, stim_channel='09  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > Rest Start (s):\", trig09, \"<\")\n",
    "    elif '19' in i: \n",
    "        with io.capture_output() as captured:\n",
    "            trig19=(mne.find_events(data, stim_channel='19  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > Rest End (s):\", trig19, \"<\")\n",
    "    elif '12' in i: \n",
    "        with io.capture_output() as captured:\n",
    "            trig12=(mne.find_events(data, stim_channel='12  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > Scrambled Start (s):\", trig12, \"<\")\n",
    "    elif '22' in i: \n",
    "        with io.capture_output() as captured:\n",
    "            trig22=(mne.find_events(data, stim_channel='22  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > Scrambled End (s):\", trig22, \"<\")\n",
    "    elif '10' in i:\n",
    "        with io.capture_output() as captured:\n",
    "            trig10=(mne.find_events(data, stim_channel='10  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > Taken Start (s):\", trig10, \"<\")\n",
    "    elif '20' in i: \n",
    "        with io.capture_output() as captured:\n",
    "            trig20=(mne.find_events(data, stim_channel='20  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > Taken End (s):\", trig20, \"<\")\n",
    "    #ERROR: other triggers found\n",
    "    elif '11' in i:\n",
    "        with io.capture_output() as captured:\n",
    "            trig11=(mne.find_events(data, stim_channel='11  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > ERROR idk what trigger 11 is:\", trig11, \"< (for HC, this was a second viewing of intact taken)\")\n",
    "    elif '99' in i:\n",
    "        with io.capture_output() as captured:\n",
    "            trig99=(mne.find_events(data, stim_channel='99  ', initial_event=True)[0, 0]/250) - (start_time)\n",
    "        print (\"    > ERROR idk what trigger 99 is:\", trig99, \"<\")        \n",
    "    else:\n",
    "        print (f'\\n____________( {i} )____________\\nERROR: idk what {i} is!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Spectral Density (PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels in EEG: 133\n",
      "\n",
      "All channel names: ['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20', 'E21', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E28', 'E29', 'E30', 'E31', 'E32', 'E33', 'E34', 'E35', 'E36', 'E37', 'E38', 'E39', 'E40', 'E41', 'E42', 'E43', 'E44', 'E45', 'E46', 'E47', 'E48', 'E49', 'E50', 'E51', 'E52', 'E53', 'E54', 'E55', 'E56', 'E57', 'E58', 'E59', 'E60', 'E61', 'E62', 'E63', 'E64', 'E65', 'E66', 'E67', 'E68', 'E69', 'E70', 'E71', 'E72', 'E73', 'E74', 'E75', 'E76', 'E77', 'E78', 'E79', 'E80', 'E81', 'E82', 'E83', 'E84', 'E85', 'E86', 'E87', 'E88', 'E89', 'E90', 'E91', 'E92', 'E93', 'E94', 'E95', 'E96', 'E97', 'E98', 'E99', 'E100', 'E101', 'E102', 'E103', 'E104', 'E105', 'E106', 'E107', 'E108', 'E109', 'E110', 'E111', 'E112', 'E113', 'E114', 'E115', 'E116', 'E117', 'E118', 'E119', 'E120', 'E121', 'E122', 'E123', 'E124', 'E125', 'E126', 'E127', 'E128', 'Vertex Reference', 'sync', '12  ', '10  ', 'STI 014']\n",
      "\n",
      "Data timing: <RawMff | signal1.bin, 133 x 259999 (1040.0 s), ~264.0 MB, data loaded>\n"
     ]
    }
   ],
   "source": [
    "print('Number of channels in EEG:', len(data.ch_names))\n",
    "print ('\\nAll channel names:', data.ch_names)\n",
    "print('\\nData timing:', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_raw_psd() is a legacy function. New code should use Raw.compute_psd().plot().\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Setting 37750 of 259999 (14.52%) samples to NaN, retaining 222249 (85.48%) samples.\n",
      "Effective window size : 8.192 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st PDS\n",
    "viz.plot_raw_psd(data, picks='eeg', exclude= ['Vertex Reference'],fmax=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1176x800 with 4 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "data.plot(duration = 30, n_channels=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter = data.copy()\n",
    "data_filter.filter(0.1, 50)\n",
    "data_filter.notch_filter(60)\n",
    "#data_filter.notch_filter(50)\n",
    "data_filter.compute_psd(picks='eeg', exclude=['Vertex Reference'], fmax=70).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Bad Electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels in EEG:\n",
      "133\n",
      "Bad Electrodes:\n",
      "[]\n",
      "all channel names\n",
      "['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20', 'E21', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E28', 'E29', 'E30', 'E31', 'E32', 'E33', 'E34', 'E35', 'E36', 'E37', 'E38', 'E39', 'E40', 'E41', 'E42', 'E43', 'E44', 'E45', 'E46', 'E47', 'E48', 'E49', 'E50', 'E51', 'E52', 'E53', 'E54', 'E55', 'E56', 'E57', 'E58', 'E59', 'E60', 'E61', 'E62', 'E63', 'E64', 'E65', 'E66', 'E67', 'E68', 'E69', 'E70', 'E71', 'E72', 'E73', 'E74', 'E75', 'E76', 'E77', 'E78', 'E79', 'E80', 'E81', 'E82', 'E83', 'E84', 'E85', 'E86', 'E87', 'E88', 'E89', 'E90', 'E91', 'E92', 'E93', 'E94', 'E95', 'E96', 'E97', 'E98', 'E99', 'E100', 'E101', 'E102', 'E103', 'E104', 'E105', 'E106', 'E107', 'E108', 'E109', 'E110', 'E111', 'E112', 'E113', 'E114', 'E115', 'E116', 'E117', 'E118', 'E119', 'E120', 'E121', 'E122', 'E123', 'E124', 'E125', 'E126', 'E127', 'E128', 'Vertex Reference', 'sync', '12  ', '10  ', 'STI 014']\n"
     ]
    }
   ],
   "source": [
    "data_filters_bads = data_filter.copy()#.pick_types(eeg=True)\n",
    "print('Number of channels in EEG:', len(data_filters_bads.ch_names))\n",
    "print('Bad Electrodes:', data_filters_bads.info['bads'])\n",
    "print ('All channel names:', data_filters_bads.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding segments below or above PTP threshold.\n",
      "automatic bads: ['E49', 'Vertex Reference', 'E1', 'E2', 'E3', 'E8', 'E14', 'E15', 'E17', 'E21', 'E22', 'E25', 'E26', 'E27', 'E32', 'E33', 'E34', 'E38', 'E39', 'E40', 'E43', 'E44', 'E45', 'E46', 'E48', 'E49', 'E50', 'E53', 'E56', 'E57', 'E58', 'E59', 'E60', 'E61', 'E63', 'E64', 'E65', 'E66', 'E69', 'E70', 'E73', 'E74', 'E75', 'E76', 'E81', 'E82', 'E83', 'E84', 'E88', 'E89', 'E90', 'E91', 'E95', 'E96', 'E97', 'E99', 'E100', 'E101', 'E102', 'E107', 'E108', 'E109', 'E113', 'E114', 'E115', 'E116', 'E119', 'E120', 'E121', 'E122', 'E123', 'E125', 'E126', 'E127', 'E128']\n",
      "75\n",
      "anotated: <Annotations | 65858 segments: BAD_flat (41015), BAD_peak (24843)>\n",
      "65858\n"
     ]
    }
   ],
   "source": [
    "### Removing Bad Electrodes ###\n",
    "\n",
    "# AUTOMATIC detecion of bad channels\n",
    "auto_annot, auto_bads = mne.preprocessing.annotate_amplitude(data_filters_bads, \n",
    "                    peak=10e-6,\n",
    "                    flat=0.01e-6 ,\n",
    "                    bad_percent=5,\n",
    "                    min_duration=0.005)\n",
    "print(f'automatic bads: {auto_bads}')\n",
    "print(len(auto_bads))\n",
    "print(f'anotated: {auto_annot}')\n",
    "print(len(auto_annot))\n",
    "data_filter_bads.info['bads'].extend(auto_bads)\n",
    "print(data_filter_bads.info['bads'])\n",
    "\n",
    "# plot & MANUAL detection of bads\n",
    "#data_filter_bads.info['bads'].extend(['E1', 'E56', 'E49', 'E78', 'E79', 'E114', 'E120', 'E121', 'E125', 'E128', 'E44', 'E54', 'E55', 'E61', 'E62'])\n",
    "viz.plot_raw_psd(data_filter_bads, picks='eeg', exclude=['Vertex Reference'], fmax=70)\n",
    "data_filter_bads.plot(duration = 10, n_channels=50) \n",
    "marked_bad = data_filter_bads.info['bads']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Interpolate (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interpolate ###\n",
    "test_interpolate = data_filter_bads.copy()\n",
    "# test_interpolate.interpolate_bads(reset_bads=True, mode='accurate')\n",
    "data_interpolated = mne.preprocessing.interpolate_bad_channels(test_interpolate, marked_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Annotate time series (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-20 17:44:59.212000+00:00\n",
      "Number of annodations made: 2\n",
      "    - Annotation names: ['BAD_ACQ_SKIP' 'BAD_ACQ_SKIP']\n",
      "    - Start times: {560.09, 971.182}\n",
      "    - Durations: [73.048 77.952]\n",
      "\n",
      "Saving .txt\n",
      "Overwriting existing file.\n",
      "    -  <Annotations | 2 segments: BAD_ACQ_SKIP (2)>\n"
     ]
    }
   ],
   "source": [
    "### Auto-annotate ###\n",
    "auto_annotations = mne.preprocessing.annotate_amplitude(\n",
    "    data_filter_bads, \n",
    "    peak=100e-6, \n",
    "    flat=1e-6, \n",
    "    bad_percent=5, \n",
    "    min_duration=0.005\n",
    "print(f'Automatic annotations: {auto_annotations}')\n",
    "print(len(auto_annotations))\n",
    "# Apply annotations to the data\n",
    "test_annotate = data_filter_bads.copy()\n",
    "test_annotate.set_annotations(auto_annotations)\n",
    "# Print details of the annotations\n",
    "print(test_annotate.annotations.orig_time)\n",
    "print(\"Number of annodations made:\", len(test_annotate.annotations))\n",
    "print(\"    - Annotation names:\", test_annotate.annotations.description)\n",
    "print(\"    - Start times:\", set(test_annotate.annotations.onset))\n",
    "print(\"    - Durations:\", test_annotate.annotations.duration)\n",
    "# Save and read annotations\n",
    "print('\\nSaving .txt')\n",
    "test_annotate.annotations.save(f'{new_path}/sub-{ID}_task-{task}_saved-annotations.txt', overwrite=True)\n",
    "annot_from_file = mne.read_annotations(f'{new_path}/sub-{ID}_task-{task}_saved-annotations.txt')\n",
    "print(\"    - \", annot_from_file)\n",
    "\n",
    "#remove annotated parts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerefrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### re-refrence ###\n",
    "data_filter_bads_reref = data_filter_bads.copy()\n",
    "data_filter_bads_reref.set_eeg_reference(ref_channels='average')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_bads_reref.compute_psd(picks='eeg', fmax=70).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_bads_reref.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete nonbrain electrods and bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove non-brain Electrodes\n",
    "data_filter_bads_reref_brainonly = data_filter_bads_reref.copy().pick_types(eeg=True)\n",
    "\n",
    "non_brain_el = ['E127', 'E126', 'E17', 'E21', 'E14', 'E25', 'E8', 'E128', \n",
    "                'E125', 'E43', 'E120', 'E48', 'E119', 'E49', 'E113', 'E81', \n",
    "                'E73', 'E88', 'E68', 'E94', 'E63', 'E99', 'E56', 'E107' ]\n",
    "\n",
    "#only add non-brain channels if not already part of noisy channels\n",
    "for e in non_brain_el: \n",
    "    if e in data_filter_bads_reref_brainonly.info['ch_names']:\n",
    "        if e not in marked_bad:\n",
    "            if e not in data_filter_bads_reref_brainonly.info['bads']:\n",
    "                ddata_filter_bads_reref_brainonly.info['bads'].append(e)\n",
    "print(data_filter_bads_reref_brainonly.info['bads'])\n",
    "\n",
    "#remove bads\n",
    "data_filter_bads_reref_brainonly.drop_channels(data_filter_bads_reref_brainonly.info['bads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_bads_reref_brainonly_interpolate = data_filter_bads_reref_brainonly.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = mne.pick_channels_regexp(raw.ch_names, regexp='EEG 05.')\n",
    "raw.plot(order=picks, n_channels=len(picks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = raw.copy().pick_types(meg=False, eeg=True, exclude=[])\n",
    "eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=False)\n",
    "\n",
    "for title, data in zip(['orig.', 'interp.'], [eeg_data, eeg_data_interp]):\n",
    "    with mne.viz.use_browser_backend('matplotlib'):\n",
    "        fig = data.plot(butterfly=True, color='#00000022', bad_color='r')\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    fig.suptitle(title, size='xx-large', weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop data by stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into events\n",
    "data_filter_bads_reref_brainonly_interpolate.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the trigger events\n",
    "events = mne.find_events(data_filter_bads_reref_brainonly_interpolate) #stim_channel='STI 014', initial_event=True)\n",
    "print(events)\n",
    "#number of eventss\n",
    "num_events = events.shape[0]\n",
    "print(\"Number of events:\", num_events)\n",
    "\n",
    "#######\n",
    "event_onsets = events[:,0] / data.info['sfreq']\n",
    "for i in range(len(event_onsets)):\n",
    "    exec(\"event_\" + str(i+1) + \" = \" + str(event_onsets[i]))\n",
    "for i in range(len(event_onsets)):\n",
    "    exec(\"print('event_' + str(i+1), 'onset:', event_\" + str(i+1) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crop (choose the event times for the associated conditions)\n",
    "if num_events == 6:\n",
    "    print(f'all data\\n  - {data.time_as_index}\\n  - {data.first_samp}\\n  - {data.last_samp}\\n  - {data.tmin}\\n  - {data.tmax}')\n",
    "    \n",
    "    rest_preproc = data_filter_bads_reref_brainonly_interpolate.copy().crop(tmin=event_onset_1, tmax=event_onset_2)\n",
    "    scrambled_preproc = data_filter_bads_reref_brainonly_interpolate.copy().crop(tmin=event_onset_3, tmax=event_onset_4)\n",
    "    taken_preproc = data_filter_bads_reref_brainonly_interpolate.copy().crop(tmin=event_onset_5, tmax=event_onset_6)\n",
    "    \n",
    "    print(f'rest\\n  - {rest_preproc.time_as_index}\\n  - {rest_preproc.first_samp}\\n  - {rest_preproc.last_samp}\\n  - {rest_preproc.tmin}\\n  - {rest_preproc.tmax}')\n",
    "    print(f'scrambled\\n  - {scrambled_preproc.time_as_index}\\n  - {scrambled_preproc.first_samp}\\n  - {scrambled_preproc.last_samp}\\n  - {scrambled_preproc.tmin}\\n  - {scrambled_preproc.tmax}')\n",
    "    print(f'taken\\n  - {taken_preproc.time_as_index}\\n  - {taken_preproc.first_samp}\\n  - {taken_preproc.last_samp}\\n  - {taken_preproc.tmin}\\n  - {taken_preproc.tmax}')\n",
    "else:\n",
    "    print(f'ERROR: You only have {num_events} events, check what events are missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save individual files (checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(f'/{project}/preproc_results')==False:\n",
    "    os.mkdir(f'{project}/preproc_results')\n",
    "if not os.path.exists(f'./{project}/preproc_results/sub-{ID}/sub-{ID}_task-{task}'):\n",
    "    os.makedirs(f'./{project}/preproc_results/sub-{ID}/sub-{ID}_task-{task}')\n",
    "    print('new directory made')\n",
    "data_filter_bads_reref_brainonly_interpolate.save(f'./{project}/preproc_results/sub-{ID}/sub-{ID}_task-{task}/preproc1.fif', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs #number of epochs for participants should have a normal distribution\n",
    "epochs = mne.make_fixed_length_epochs(data_filter_bads_reref_brainonly.copy(), duration=10, reject_by_annotation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Reject epochs with amplitude bigger than 2000 µVolt\n",
    "#Peak to peak amplitude on brain scalp > 2000 µVolt are epochs not linked with physiological causes, physiological amplitude accepted < 800 µVolt\n",
    "epochs_clean = epochs.copy()#.load_data()\n",
    "epochs_clean.drop_bad({'eeg':2000*1e-6})\n",
    "epochs_clean.plot_drop_log()\n",
    "epochs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ##### Manual selection of ICA components\n",
    "#Number of components = 30 because it's better to have as many components as possible (up to the nb of electrodes ~100 after clearing and rejection of non brain) 30 remains a good compromise\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs, corrmap)\n",
    "ica = ICA(n_components=30, max_iter='auto', random_state=97)\n",
    "ica.fit(epochs_clean)\n",
    "ica.plot_sources(epochs_clean)\n",
    "ica.plot_components(inst=epochs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main artifacts, eyes and jaw muscle contractions and clear non physiological artifacts (machine at the ICU for example). Coordinates in the variance table, x corresponds to epochs, y corresponds to variance. Enables to identify if the component has an impact on the variance all recording long or rather if it is a specific epoch that we need to reject. we need to decide if it is a component to remove or rather an epoch.\n",
    "ica.plot_properties(epochs_clean, picks=ica.exclude)\n",
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check which component to remove:\n",
    "ica.exclude\n",
    "len(ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove component definetely\n",
    "epochs_clean.load_data()\n",
    "eeg_postica= ica.apply(epochs_clean.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot to compare both signals pre and post ICA\n",
    "epochs_clean.plot(title='raw', n_epochs=3, n_channels=60, scalings=20e-6)\n",
    "eeg_postica.plot(title='ICA correction', n_epochs=3, n_channels=60, scalings=20e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save individual files (Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save final file\n",
    "# if os.path.isdir('preproc_results')==False:\n",
    "#     os.mkdir('preproc_results')\n",
    "# if not os.path.exists(f'./preproc_results/sub-{ID}/sub-{ID}_task-{task}'):\n",
    "#     os.makedirs(f'./preproc_results/sub-{ID}/sub-{ID}_task-{task}')\n",
    "#     print('new directory made')\n",
    "# data_filter_bads_reref_brainonly.save(f'./preproc_results/sub-{ID}/sub-{ID}_task-{task}/data_filter_bads_reref_brainonly_epoch_ICA.fif', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save previously loaded figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}'):\n",
    "    os.makedirs(f'./{project}/out_figures/sub-{ID}/task-{task}')\n",
    "    print('new directory made')\n",
    "\n",
    "#data\n",
    "step = 'data'\n",
    "data.info['bads'].extend(['Vertex Reference'])\n",
    "data.compute_psd(picks='eeg', fmax=70).plot()\n",
    "data.info['bads'].remove('Vertex Reference')\n",
    "data.info['bads']\n",
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png'):\n",
    "    plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "    print(f'{step} PSD saved')\n",
    "else:\n",
    "    print(f'{step}.png already exists, Would you like to overwrite it?')\n",
    "    yesorno = input('type \"yes\" to overwrite or \"no\" to cancel:')\n",
    "    if yesorno == 'yes':\n",
    "        plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "        print('PSD was overwritten')\n",
    "    elif yesorno == 'no':\n",
    "        print('Canceled')\n",
    "\n",
    "#filter\n",
    "step = 'data_filter'\n",
    "data_filter.info['bads'].extend(['Vertex Reference'])\n",
    "data_filter.compute_psd(picks='eeg', fmax=70).plot()\n",
    "data_filter.info['bads'].remove('Vertex Reference')\n",
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png'):\n",
    "    plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "    print(f'{step} PSD saved')\n",
    "else:\n",
    "    print(f'{step}.png already exists, Would you like to overwrite it?')\n",
    "    yesorno = input('type \"yes\" to overwrite or \"no\" to cancel:')\n",
    "    if yesorno == 'yes':\n",
    "        plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "        print('PSD was overwritten')\n",
    "    elif yesorno == 'no':\n",
    "        print('Canceled')\n",
    "\n",
    "#bads\n",
    "step = 'data_filter_bads'\n",
    "data_filter_bads.info['bads'].extend(['Vertex Reference'])\n",
    "data_filter_bads.compute_psd(picks='eeg', fmax=70).plot()\n",
    "data_filter_bads.info['bads'].remove('Vertex Reference')\n",
    "data_filter_bads.info['bads']\n",
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png'):\n",
    "    plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "    print(f'{step} PSD saved')\n",
    "else:\n",
    "    print(f'{step}.png already exists, Would you like to overwrite it?')\n",
    "    yesorno = input('type \"yes\" to overwrite or \"no\" to cancel:')\n",
    "    if yesorno == 'yes':\n",
    "        plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "        print('PSD was overwritten')\n",
    "    elif yesorno == 'no':\n",
    "        print('Canceled')\n",
    "if not os.path.exists(f'{new_path}/sub-{ID}_task-{task}_marked_bads.txt'):\n",
    "    open(f'{new_path}/sub-{ID}_task-{task}_marked_bads.txt', 'x')\n",
    "    with open (f'{new_path}/sub-{ID}_task-{task}_marked_bads.txt', 'w') as badsfile:\n",
    "        badsfile.write('\\n'.join(marked_bad))\n",
    "        print('.txt file created')\n",
    "else:\n",
    "    with open (f'{new_path}/sub-{ID}_task-{task}_marked_bads.txt', 'w') as outfile:\n",
    "        outfile.write('\\n'.join(marked_bad))\n",
    "        print('marked_bads.txt was updated')\n",
    "        \n",
    "#reref\n",
    "step = 'data_filter_bads_reref'\n",
    "data_filter_bads_reref.compute_psd(picks='eeg', fmax=70).plot()\n",
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png'):\n",
    "    plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "    print(f'{step} PSD saved')\n",
    "else:\n",
    "    print(f'{step}.png already exists, Would you like to overwrite it?')\n",
    "    yesorno = input('type \"yes\" to overwrite or \"no\" to cancel:')\n",
    "    if yesorno == 'yes':\n",
    "        plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "        print('PSD was overwritten')\n",
    "    elif yesorno == 'no':\n",
    "        print('Canceled')\n",
    "\n",
    "#brainonly\n",
    "step = 'data_filter_bads_reref_brainonly'\n",
    "data_filter_bads_reref_brainonly.compute_psd(picks='eeg', fmax=70).plot()\n",
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png'):\n",
    "    plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "    print(f'{step} PSD saved')\n",
    "else:\n",
    "    print(f'{step}.png already exists, Would you like to overwrite it?')\n",
    "    yesorno = input('type \"yes\" to overwrite or \"no\" to cancel:')\n",
    "    if yesorno == 'yes':\n",
    "        plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "        print('PSD was overwritten')\n",
    "    elif yesorno == 'no':\n",
    "        print('Canceled')\n",
    "\n",
    "#interpolate\n",
    "step = 'data_filter_bads_reref_brainonly_interpolate'\n",
    "data_filter_bads_reref_brainonly_interpolate.compute_psd(picks='eeg', fmax=70).plot()\n",
    "if not os.path.exists(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png'):\n",
    "    plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "    print(f'{step} PSD saved')\n",
    "else:\n",
    "    print(f'{step}.png already exists, Would you like to overwrite it?')\n",
    "    yesorno = input('type \"yes\" to overwrite or \"no\" to cancel:')\n",
    "    if yesorno == 'yes':\n",
    "        plt.savefig(f'./{project}/out_figures/sub-{ID}/task-{task}/sub-{ID}_task-{task}_PSD_{step}.png')\n",
    "        print('PSD was overwritten')\n",
    "    elif yesorno == 'no':\n",
    "        print('Canceled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
